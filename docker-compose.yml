version: "3.9"

services:
  # MeiliSearch Service
  meilisearch:
    image: getmeili/meilisearch:v1.27.0
    container_name: meilisearch-demo-service
    restart: unless-stopped
    command: >
      meilisearch
      --env production
      --master-key "${MEILI_MASTER_KEY:-ybO-TnedO7pjj2kzykVeeWOA2SCb39j1VsLIdEkl-j0}"
      --schedule-snapshot
      --snapshot-dir /meili_data/snapshots
    ports:
      - "${MEILI_PORT:-7700}:7700" # host:container
    volumes:
      - meili_data:/meili_data
    networks:
      - semantic-net
    healthcheck:
      test: ["CMD-SHELL", "curl -sSf http://localhost:7700/health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  # Ollama Service (For Nomic-Embed-Text)
  ollama:
    build:
      context: .
      dockerfile: docker/ollama.Dockerfile
    image: bloggy-ollama:0.13.1-rc0
    container_name: ollama-demo-service
    restart: unless-stopped
    ports:
      - "11434:11434"
    environment:
      OLLAMA_VULKAN: "0"
      OLLAMA_GPU_OVERHEAD: "0"
    volumes:
      - ollama_models:/root/.ollama
    networks:
      - semantic-net
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:11434/ || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 60s

  # Ollama Init Service - Pulls the model after Ollama is ready
  ollama-init:
    image: bloggy-ollama:0.13.1-rc0
    container_name: ollama-init-service
    depends_on:
      ollama:
        condition: service_healthy
    environment:
      OLLAMA_HOST: "http://ollama:11434"
    volumes:
      - ollama_models:/root/.ollama
    networks:
      - semantic-net
    entrypoint: ["/bin/sh", "-c"]
    command:
      - |
        echo "Waiting for Ollama to be fully ready..."
        sleep 20
        echo "Pulling nomic-embed-text:v1.5 model..."
        if ollama pull nomic-embed-text:v1.5; then
          echo "Model pull completed successfully."
        else
          echo "Model pull failed or already exists. Check if the model is available."
        fi
    restart: "no"

  # Backend Service (Your .NET API from server)
  backend:
    build:
      context: ./server/Bloggy  # Points to the server folder for the backend code
      dockerfile: Bloggy.Api/Dockerfile  # Path to Dockerfile relative to context
    container_name: backend-demo-service
    restart: unless-stopped
    ports:
      - "${BACKEND_PORT:-5010}:5010"
    environment:
      ASPNETCORE_ENVIRONMENT: "${ASPNETCORE_ENVIRONMENT:-Development}"
      MEILI_URL: "http://meilisearch:7700"
      MEILI_API_KEY: "${MEILI_API_KEY:-2a4ba9e10ce6288ba8170d4851cc334426fccf2b8355088e56b5e966e3865c03}" # meilisearch admin API Key
      MEILI_SEARCH_API: "${MEILI_SEARCH_API:-4b25ace4d3329123a133496256965279cd811706c8dfd5750fe0fe1145665207}" # meilisearch search API Key
      ASPNETCORE_URLS: "http://+:5010"
      OLLAMA_URL: "http://ollama:11434"
      VITE_FRONTEND_URL: "${VITE_FRONTEND_URL:-http://frontend-demo-service:5173}" # comment out for local testing
      VITE_BACKEND_URL: "http://localhost:5010"
    depends_on:
      meilisearch:
        condition: service_healthy
      ollama:
        condition: service_healthy
    networks:
      - semantic-net
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5010/health || exit 1"]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 60s

  # Frontend Service (React + Vite from client)
  frontend:
    build:
      context: ./client  # Points to the client folder for the frontend code
      dockerfile: Dockerfile.prod  # Use production Dockerfile
    container_name: frontend-demo-service
    restart: unless-stopped
    ports:
      - "${FRONTEND_PORT:-80}:80"  # nginx serves on port 80
    environment:
      VITE_BACKEND_URL: "${VITE_BACKEND_URL:-http://backend-demo-service:5010}"  # Set the backend URL for the frontend to consume the API
      # VITE_BACKEND_URL: "http://localhost:5010"  # Set the backend URL for the frontend to consume the API for local testing
    depends_on:
      backend:
        condition: service_healthy
    networks:
      - semantic-net

volumes:
  meili_data:
  ollama_models:

networks:
  semantic-net:
    driver: bridge
